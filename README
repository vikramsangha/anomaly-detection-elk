# 🚀 Log Anomaly Detection Project

This project provides a system for detecting anomalies in **test automation logs** using the **Elastic Stack** (Elasticsearch, Logstash, Kibana) and a custom Python script.

---

## 📂 Project Structure

```text
.
├── anomaly_report.py        # Python script for analyzing anomaly detection results
├── docker-compose.yml       # Docker Compose file to set up Elastic Stack
├── logstash.conf            # Logstash configuration file to process log data
├── logs/                    # Example log files (NDJSON format: test-automation-logs-YYYYMMDD.ndjson)
├── reports/                 # Generated reports (with a README)
├── scripts/                 # Helper scripts
│   ├── create-ml-job.sh     # Script to create the ML job in Elasticsearch
│   └── init-license.sh      # Script to initialize the Elastic license
└── templates/               # Templates
    └── test-logs-template.json  # Elasticsearch index template
```

---

## 🛠 Requirements

- [Docker](https://docs.docker.com/get-docker/) and Docker Compose
- Basic knowledge of the **Elastic Stack**

---

## 🚦 Usage

### 1. Start the Elastic Stack
```bash
docker-compose up -d
```

### 2. Initialize the License (if required)
```bash
./scripts/init-license.sh
```

### 3. Load Log Data
Place your `.ndjson` files in the `logs/` directory.  
Logstash will read these and push them into Elasticsearch (config in `logstash.conf`).

### 4. Create the Machine Learning Job
```bash
./scripts/create-ml-job.sh
```

### 5. Analyze Anomaly Detection Results
```bash
python anomaly_report.py
```
Reports will be available in the `reports/` directory.

### 6. Visualize in Kibana
Open [http://localhost:5601](http://localhost:5601) in your browser to explore the data and ML results.

---

## 📑 Log File Format

- Logs are stored in **NDJSON format**  
- Each line = one JSON object  
- `logstash.conf` parses this format and maps fields into Elasticsearch indices  

---

## ⚙️ Customization

- **Logstash Pipeline:** edit `logstash.conf` to handle new log formats or transformations  
- **ML Job Definition:** tweak `scripts/create-ml-job.sh` to adjust detectors, bucket spans, influencers, etc.  
- **Reports:** extend `anomaly_report.py` for deeper analytics or custom report generation  

---

## 📌 Next Steps

- Add CI/CD integration for automated anomaly detection  
- Enhance visualization dashboards in Kibana  
- Extend support for multiple log formats  

---
